{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7e0915-2443-4177-91cb-dbcdc4b5fafb",
   "metadata": {},
   "source": [
    "# 普通稀疏卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1478069-c06a-4e66-b8ec-a42410220854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spconv.pytorch as spconv\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d242712-4885-4ee7-a6bd-eb0449cd30d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4, 1])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "features = torch.tensor([[1], [2], [3]])# your features with shape [N, num_channels]\n",
    "indices = torch.tensor([[0, 0, 0, 0], [0, 1, 1, 0], [0, 3, 3, 0]], dtype=torch.int32)# your indices/coordinates with shape [N, ndim + 1], batch index must be put in indices[:, 0]\n",
    "# 第一个位置是batch_idx，后四位是features对应的索引值\n",
    "spatial_shape = torch.tensor([4, 4, 1])# spatial shape of your sparse tensor, spatial_shape[i] is shape of indices[:, 1 + i].\n",
    "batch_size = 1# batch size of your sparse tensor.\n",
    "x = spconv.SparseConvTensor(features, indices, spatial_shape, batch_size)\n",
    "x_dense_NCHW = x.dense() # convert sparse tensor to dense NCHW tensor.\n",
    "print(x_dense_NCHW.shape)\n",
    "print(x_dense_NCHW.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acfa9cd5-aa47-4453-a6c5-8536d7e55d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spconv.pytorch as spconv\n",
    "from torch import nn\n",
    "class ExampleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = spconv.SparseSequential(\n",
    "            spconv.SparseConv3d(1, 1, 3, 1, 1, bias=False), \n",
    "        )\n",
    "\n",
    "    def forward(self, sparse_input):\n",
    "        x_sp = spconv.SparseConvTensor.from_dense(sparse_input.reshape(-1, 1, 4, 4, 1))\n",
    "        return self.net(x_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953fcc0c-d495-4ca0-b742-365a0b1e974e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[3., 3., 2., 0.],\n",
       "           [3., 3., 2., 0.],\n",
       "           [2., 2., 5., 3.],\n",
       "           [0., 0., 3., 3.]]]]], device='cuda:0', grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ExampleNet()\n",
    "model.net[0].weight.data.fill_(1)\n",
    "model.to(device)\n",
    "\n",
    "x_dense_NCHW = x_dense_NCHW.to(torch.float32).to(device) # 必须转类型\n",
    "\n",
    "output = model(x_dense_NCHW)\n",
    "output.dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79c6da-9f4f-4161-891e-5592d7949f5b",
   "metadata": {},
   "source": [
    "# 二、SubM卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36a33246-67c1-4655-abaa-0105569d6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spconv.pytorch as spconv\n",
    "from torch import nn\n",
    "class ExampleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = spconv.SparseSequential(\n",
    "            spconv.SubMConv3d(1, 1, 3, 1, 1, bias=False), \n",
    "        )\n",
    "\n",
    "    def forward(self, sparse_input):\n",
    "        x_sp = spconv.SparseConvTensor.from_dense(sparse_input.reshape(-1, 1, 4, 4, 1))\n",
    "        return self.net(x_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f108b1f-cbf9-4ffe-9954-ca065c4deac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[3., 0., 0., 0.],\n",
       "           [0., 3., 0., 0.],\n",
       "           [0., 0., 0., 0.],\n",
       "           [0., 0., 0., 3.]]]]], device='cuda:0', grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ExampleNet()\n",
    "model.net[0].weight.data.fill_(1)\n",
    "model.to(device)\n",
    "\n",
    "x_dense_NCHW = x_dense_NCHW.to(torch.float32).to(device) # 必须转类型\n",
    "\n",
    "output = model(x_dense_NCHW)\n",
    "output.dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47940da-a951-4523-823a-97a1e13abb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
