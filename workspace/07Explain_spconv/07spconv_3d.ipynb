{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7e0915-2443-4177-91cb-dbcdc4b5fafb",
   "metadata": {},
   "source": [
    "# 普通稀疏卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0a9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spconv-cu113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed9a58",
   "metadata": {},
   "source": [
    "- https://github.com/traveller59/spconv\n",
    "- https://github.com/traveller59/spconv/blob/master/docs/USAGE.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1478069-c06a-4e66-b8ec-a42410220854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spconv.pytorch as spconv\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a966a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export CUDA_VISIBLE_DEVICES=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c2cd6",
   "metadata": {},
   "source": [
    "- 想象成，经过体素化后，3D世界被划分为4*4*1的格子\n",
    "- 有的格子是没有特征的。有的格子特征features分别为[1] [2] [3]\n",
    "- 索引是[0, 0, 0], [1, 1, 0], [3, 3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d242712-4885-4ee7-a6bd-eb0449cd30d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseConvTensor[shape=torch.Size([3, 1])]\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "torch.Size([1, 1, 4, 4, 1])\n",
      "torch.int64\n",
      "tensor([[[[[1],\n",
      "           [0],\n",
      "           [0],\n",
      "           [0]],\n",
      "\n",
      "          [[0],\n",
      "           [2],\n",
      "           [0],\n",
      "           [0]],\n",
      "\n",
      "          [[0],\n",
      "           [0],\n",
      "           [0],\n",
      "           [0]],\n",
      "\n",
      "          [[0],\n",
      "           [0],\n",
      "           [0],\n",
      "           [3]]]]])\n"
     ]
    }
   ],
   "source": [
    "features = torch.tensor([[1], [2], [3]])# your features with shape [N, num_channels]\n",
    "indices = torch.tensor([[0, 0, 0, 0], [0, 1, 1, 0], [0, 3, 3, 0]], dtype=torch.int32)# your indices/coordinates with shape [N, ndim + 1], batch index must be put in indices[:, 0]\n",
    "# 第一个位置是batch_idx，后四位是features对应的索引值\n",
    "spatial_shape = torch.tensor([4, 4, 1])# spatial shape of your sparse tensor, spatial_shape[i] is shape of indices[:, 1 + i].\n",
    "batch_size = 1# batch size of your sparse tensor.\n",
    "x = spconv.SparseConvTensor(features, indices, spatial_shape, batch_size)\n",
    "print(x)\n",
    "print(x.features)\n",
    "x_dense_NCHW = x.dense() # convert sparse tensor to dense NCHW tensor.\n",
    "print(x_dense_NCHW.shape)\n",
    "print(x_dense_NCHW.dtype)\n",
    "print(x_dense_NCHW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acfa9cd5-aa47-4453-a6c5-8536d7e55d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spconv.pytorch as spconv\n",
    "from torch import nn\n",
    "class ExampleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = spconv.SparseSequential(\n",
    "            spconv.SparseConv3d(1, 1, 3, 1, 1, bias=False), \n",
    "        )\n",
    "\n",
    "    def forward(self, sparse_input):\n",
    "        x_sp = spconv.SparseConvTensor.from_dense(sparse_input.reshape(-1, 1, 4, 4, 1))\n",
    "        return self.net(x_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b18f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953fcc0c-d495-4ca0-b742-365a0b1e974e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[3., 3., 2., 0.],\n",
       "           [3., 3., 2., 0.],\n",
       "           [2., 2., 5., 3.],\n",
       "           [0., 0., 3., 3.]]]]], device='cuda:0', grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ExampleNet()\n",
    "model.net[0].weight.data.fill_(1)\n",
    "model.to(device)\n",
    "\n",
    "x_dense_NCHW = x_dense_NCHW.to(torch.float32).to(device) # 必须转类型\n",
    "\n",
    "output = model(x_dense_NCHW)\n",
    "output.dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79c6da-9f4f-4161-891e-5592d7949f5b",
   "metadata": {},
   "source": [
    "# 二、SubM卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a33246-67c1-4655-abaa-0105569d6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spconv.pytorch as spconv\n",
    "from torch import nn\n",
    "class ExampleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = spconv.SparseSequential(\n",
    "            spconv.SubMConv3d(1, 1, 3, 1, 1, bias=False), \n",
    "        )\n",
    "\n",
    "    def forward(self, sparse_input):\n",
    "        x_sp = spconv.SparseConvTensor.from_dense(sparse_input.reshape(-1, 1, 4, 4, 1))\n",
    "        return self.net(x_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f108b1f-cbf9-4ffe-9954-ca065c4deac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[3., 0., 0., 0.],\n",
       "           [0., 3., 0., 0.],\n",
       "           [0., 0., 0., 0.],\n",
       "           [0., 0., 0., 3.]]]]], device='cuda:0', grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ExampleNet()\n",
    "model.net[0].weight.data.fill_(1)\n",
    "model.to(device)\n",
    "\n",
    "x_dense_NCHW = x_dense_NCHW.to(torch.float32).to(device) # 必须转类型\n",
    "\n",
    "output = model(x_dense_NCHW)\n",
    "output.dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f37f5",
   "metadata": {},
   "source": [
    "- 希望这个案例，能够让大家知道，点云体素化后，\n",
    "    - 有了features 和 coors ，coors通常是batch_size，X,Y,Z\n",
    "\n",
    "- 使得我们虽然没有细看稀疏卷积网络，但是能对他有个大概的印象。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481a3c58",
   "metadata": {},
   "source": [
    "# 其他，不要看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d47940da-a951-4523-823a-97a1e13abb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca328592",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Linear.__new__(nn.Linear)\n",
    "b = nn.Linear(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce8c45ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=3, bias=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for k, v in vars(b).items():\n",
    "    i+=1\n",
    "    setattr(a, k, v)\n",
    "    if i == 11:\n",
    "        print(\"1\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aded1740",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'torch.LongTensor' as parameter 'bias' (torch.nn.Parameter or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39msetattr\u001b[39m(a, \u001b[39m\"\u001b[39m\u001b[39min_features\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[39msetattr\u001b[39m(a, \u001b[39m\"\u001b[39m\u001b[39mout_features\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[39msetattr\u001b[39;49m(a, \u001b[39m\"\u001b[39;49m\u001b[39mbias\u001b[39;49m\u001b[39m\"\u001b[39;49m, torch\u001b[39m.\u001b[39;49mtensor(\u001b[39m3\u001b[39;49m))\n\u001b[1;32m      4\u001b[0m \u001b[39m# weight = torch.ones((3, 1))\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# print(weight.shape)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39msetattr\u001b[39m(a, \u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1.\u001b[39m, \u001b[39m2.\u001b[39m, \u001b[39m3.\u001b[39m]])\u001b[39m.\u001b[39mT)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1198\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[39melif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m name \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   1197\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1198\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot assign \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m as parameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1199\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39m(torch.nn.Parameter or None expected)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1200\u001b[0m                         \u001b[39m.\u001b[39mformat(torch\u001b[39m.\u001b[39mtypename(value), name))\n\u001b[1;32m   1201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_parameter(name, value)\n\u001b[1;32m   1202\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot assign 'torch.LongTensor' as parameter 'bias' (torch.nn.Parameter or None expected)"
     ]
    }
   ],
   "source": [
    "setattr(a, \"in_features\", 1)\n",
    "setattr(a, \"out_features\", 3)\n",
    "setattr(a, \"bias\", torch.tensor(3))\n",
    "# weight = torch.ones((3, 1))\n",
    "# print(weight.shape)\n",
    "setattr(a, \"weight\", torch.tensor([[1., 2., 3.]]).T)\n",
    "setattr(a, \"device\", \"cuda:0\")\n",
    "setattr(a, \"dtype\", torch.float32)\n",
    "setattr(a, \"aaa\", 3)\n",
    "\n",
    "print(getattr(a, \"in_features\"))\n",
    "print(getattr(a, \"out_features\"))\n",
    "print(getattr(a, \"bias\"))\n",
    "print(getattr(a, \"weight\"))\n",
    "\n",
    "intput = torch.ones((1))\n",
    "print(intput.shape)\n",
    "res = a.forward(intput)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19b73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
