{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_quantization.nn as quant_nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Bottleneck(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个只有resnet  layer1[0]及之前部分的网络\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myModel, self).__init__()\n",
    "        resnetmodel = models.resnet50(pretrained=True)\n",
    "        self.conv1 = resnetmodel.conv1\n",
    "        self.bn1 = resnetmodel.bn1\n",
    "        self.relu = resnetmodel.relu\n",
    "        self.maxpool = resnetmodel.maxpool\n",
    "        self.layer1 = resnetmodel.layer1[0]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        return x\n",
    "\n",
    "model = myModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一次导出onnx，查看\n",
    "# input1 = torch.zeros((1, 3, 224, 224))\n",
    "# output = model(input1)\n",
    "# torch.onnx.export(model, input1, \"resnet50.onnx\", verbose=True, input_names=[\"input\"], output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantize\n",
    "from pytorch_quantization import quant_modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==[orig_mod]==                                                    <module 'torch.nn' from '/usr/local/lib/python3.8/dist-packages/torch/nn/__init__.py'>\n",
      "==[item.mod_name]==                                               Conv1d\n",
      "==[item.replace_mod]==                                            <class 'pytorch_quantization.nn.modules.quant_conv.QuantConv1d'>\n",
      "==[item]==                                                        quant_entry(orig_mod=<module 'torch.nn' from '/usr/local/lib/python3.8/dist-packages/torch/nn/__init__.py'>, mod_name='Conv1d', replace_mod=<class 'pytorch_quantization.nn.modules.quant_conv.QuantConv1d'>)\n",
      "==[initialize前,default_quant_desc_input]==                        QuantDescriptor(8bit fake axis= per-tensor)\n",
      "==[initialize前,default_quant_desc_input.calib_method]==           max <---------设置calib_method前是max\n",
      "==[initialize前,default_quant_desc_weight]==                       QuantDescriptor(8bit fake axis=0)\n",
      "==[initialize前,default_quant_desc_weight.calib_method]==          max\n",
      "\n",
      "！！修改前，已经有default_quant_desc_input 和 default_quant_desc_weight了！！\n",
      "！！修改后，default_quant_desc_input的校准器设置为histogram！！\n",
      "\n",
      "==[initialize后,default_quant_desc_input]==                        QuantDescriptor(8bit fake axis= per-tensor)\n",
      "==[initialize后,default_quant_desc_input.calib_method]==           histogram <---------设置calib_method后是histogram\n",
      "==[initialize后,default_quant_desc_weight]==                       QuantDescriptor(8bit fake axis=0)\n",
      "==[initialize后,default_quant_desc_weight.calib_method]==          max\n"
     ]
    }
   ],
   "source": [
    "# 1.0 主題：解释initialize\n",
    "\n",
    "# 1.1 打印看一下namedtuple是什么样子。\n",
    "for item in quant_modules._DEFAULT_QUANT_MAP:\n",
    "    print(f\"==[orig_mod]==\".ljust(65), item.orig_mod)\n",
    "    # print(f\"==[torch.nn]==\\t\\t\",torch.nn) # 与上方代码结果一致\n",
    "    print(f\"==[item.mod_name]==\".ljust(65), item.mod_name)\n",
    "    print(f\"==[item.replace_mod]==\".ljust(65), item.replace_mod)\n",
    "    print(f\"==[item]==\".ljust(65), item) # namedtuple\n",
    "    break\n",
    "\n",
    "# 1.4 initialize前的信息，作为对比\n",
    "for item in quant_modules._DEFAULT_QUANT_MAP:\n",
    "    print(f\"==[initialize前,default_quant_desc_input]==\".ljust(65), item.replace_mod.default_quant_desc_input)\n",
    "    print(f\"==[initialize前,default_quant_desc_input.calib_method]==\".ljust(65), item.replace_mod.default_quant_desc_input.calib_method, \"<---------设置calib_method前是max\")\n",
    "    \"\"\"vars(item.replace_mod.default_quant_desc_input).items()的結果\n",
    "    dict_items([('_num_bits', 8), ('_name', None), ('_fake_quant', True), ('_axis', None), ('_learn_amax', False), \n",
    "    ('_amax', None), ('_scale_amax', None), ('_calib_method', 'max'), ('_unsigned', False), ('_narrow_range', False)])\n",
    "    \"\"\"\n",
    "    print(f\"==[initialize前,default_quant_desc_weight]==\".ljust(65), item.replace_mod.default_quant_desc_weight)\n",
    "    print(f\"==[initialize前,default_quant_desc_weight.calib_method]==\".ljust(65), item.replace_mod.default_quant_desc_weight.calib_method)\n",
    "    # print(item.replace_mod.input_quantizer)\n",
    "    # print(item.replace_mod.weight_quantizer)\n",
    "    break\n",
    "\n",
    "# 1.2 把initialize从bevfusion中拷贝过来\n",
    "quantize.initialize()\n",
    "\n",
    "# 1.5 \n",
    "print(\"\\n！！修改前，已经有default_quant_desc_input 和 default_quant_desc_weight了！！\")\n",
    "print(\"！！修改后，default_quant_desc_input的校准器设置为histogram！！\\n\")\n",
    "for item in quant_modules._DEFAULT_QUANT_MAP:\n",
    "    print(f\"==[initialize后,default_quant_desc_input]==\".ljust(65), item.replace_mod.default_quant_desc_input)\n",
    "    print(f\"==[initialize后,default_quant_desc_input.calib_method]==\".ljust(65), item.replace_mod.default_quant_desc_input.calib_method, \"<---------设置calib_method后是histogram\")\n",
    "    print(f\"==[initialize后,default_quant_desc_weight]==\".ljust(65), item.replace_mod.default_quant_desc_weight)\n",
    "    print(f\"==[initialize后,default_quant_desc_weight.calib_method]==\".ljust(65), item.replace_mod.default_quant_desc_weight.calib_method)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.0 主题：解释\n",
    "\n",
    "# 2.1 什么是model._modules\n",
    "# print(model)\n",
    "# print(model._modules) #是一个OrderedDict类型。\n",
    "quantize.replace_to_quantization_module(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel(\n",
       "  (conv1): QuantConv2d(\n",
       "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
       "    (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "    (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Bottleneck(\n",
       "    (conv1): QuantConv2d(\n",
       "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "    )\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): QuantConv2d(\n",
       "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "    )\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): QuantConv2d(\n",
       "      64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "    )\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): QuantConv2d(\n",
       "        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "        (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cuda:0),\n",
      "      %conv1.weight : Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=1, device=cuda:0),\n",
      "      %bn1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %bn1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layer1.conv1.weight : Float(64, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.bn1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.bn1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.bn1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layer1.bn1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layer1.conv2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.bn2.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.bn2.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.bn2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layer1.bn2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layer1.conv3.weight : Float(256, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.bn3.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.bn3.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.bn3.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layer1.bn3.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layer1.downsample.0.weight : Float(256, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.downsample.1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.downsample.1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %layer1.downsample.1.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %layer1.downsample.1.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %102 : Char(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %103 : Char(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %104 : Char(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %105 : Char(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %106 : Char(256, strides=[1], requires_grad=0, device=cuda:0)):\n",
      "  %31 : Float(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %32 : Char(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %33 : Char(1, 3, 224, 224, strides=[150528, 50176, 224, 1], device=cpu) = onnx::QuantizeLinear(%input, %31, %32)\n",
      "  %34 : Float(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %35 : Char(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %36 : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cuda:0) = onnx::DequantizeLinear(%33, %34, %35) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %37 : Float(64, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>]() # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %40 : Char(64, 3, 7, 7, strides=[147, 49, 7, 1], device=cpu) = onnx::QuantizeLinear[axis=0](%conv1.weight, %37, %102)\n",
      "  %41 : Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=0, device=cuda:0) = onnx::DequantizeLinear[axis=0](%40, %37, %102) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %42 : Float(1, 64, 112, 112, strides=[802816, 12544, 112, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%36, %41) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/quant_conv.py:130:0\n",
      "  %43 : Float(1, 64, 112, 112, strides=[802816, 12544, 112, 1], requires_grad=0, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%42, %bn1.weight, %bn1.bias, %bn1.running_mean, %bn1.running_var) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2282:0\n",
      "  %44 : Float(1, 64, 112, 112, strides=[802816, 12544, 112, 1], requires_grad=0, device=cuda:0) = onnx::Relu(%43) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %45 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::MaxPool[ceil_mode=0, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%44) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:719:0\n",
      "  %46 : Float(device=cpu) = onnx::Constant[value={0.00667123}]()\n",
      "  %47 : Char(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %48 : Char(1, 64, 56, 56, strides=[200704, 3136, 56, 1], device=cpu) = onnx::QuantizeLinear(%45, %46, %47)\n",
      "  %49 : Float(device=cpu) = onnx::Constant[value={0.00667123}]()\n",
      "  %50 : Char(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %51 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::DequantizeLinear(%48, %49, %50) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %52 : Float(64, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>]() # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %55 : Char(64, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::QuantizeLinear[axis=0](%layer1.conv1.weight, %52, %103)\n",
      "  %56 : Float(64, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0) = onnx::DequantizeLinear[axis=0](%55, %52, %103) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %57 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%51, %56) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/quant_conv.py:130:0\n",
      "  %58 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%57, %layer1.bn1.weight, %layer1.bn1.bias, %layer1.bn1.running_mean, %layer1.bn1.running_var) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2282:0\n",
      "  %59 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::Relu(%58) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %60 : Float(device=cpu) = onnx::Constant[value={0.00411177}]()\n",
      "  %61 : Char(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %62 : Char(1, 64, 56, 56, strides=[200704, 3136, 56, 1], device=cpu) = onnx::QuantizeLinear(%59, %60, %61)\n",
      "  %63 : Float(device=cpu) = onnx::Constant[value={0.00411177}]()\n",
      "  %64 : Char(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %65 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::DequantizeLinear(%62, %63, %64) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %66 : Float(64, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>]() # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %69 : Char(64, 64, 3, 3, strides=[576, 9, 3, 1], device=cpu) = onnx::QuantizeLinear[axis=0](%layer1.conv2.weight, %66, %104)\n",
      "  %70 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0) = onnx::DequantizeLinear[axis=0](%69, %66, %104) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %71 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%65, %70) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/quant_conv.py:130:0\n",
      "  %72 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%71, %layer1.bn2.weight, %layer1.bn2.bias, %layer1.bn2.running_mean, %layer1.bn2.running_var) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2282:0\n",
      "  %73 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::Relu(%72) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %74 : Float(device=cpu) = onnx::Constant[value={0.0105871}]()\n",
      "  %75 : Char(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %76 : Char(1, 64, 56, 56, strides=[200704, 3136, 56, 1], device=cpu) = onnx::QuantizeLinear(%73, %74, %75)\n",
      "  %77 : Float(device=cpu) = onnx::Constant[value={0.0105871}]()\n",
      "  %78 : Char(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %79 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::DequantizeLinear(%76, %77, %78) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %80 : Float(256, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>]() # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %83 : Char(256, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::QuantizeLinear[axis=0](%layer1.conv3.weight, %80, %105)\n",
      "  %84 : Float(256, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0) = onnx::DequantizeLinear[axis=0](%83, %80, %105) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %85 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%79, %84) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/quant_conv.py:130:0\n",
      "  %86 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%85, %layer1.bn3.weight, %layer1.bn3.bias, %layer1.bn3.running_mean, %layer1.bn3.running_var) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2282:0\n",
      "  %87 : Float(device=cpu) = onnx::Constant[value={0.00667123}]()\n",
      "  %88 : Char(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %89 : Char(1, 64, 56, 56, strides=[200704, 3136, 56, 1], device=cpu) = onnx::QuantizeLinear(%45, %87, %88)\n",
      "  %90 : Float(device=cpu) = onnx::Constant[value={0.00667123}]()\n",
      "  %91 : Char(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %92 : Float(1, 64, 56, 56, strides=[200704, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::DequantizeLinear(%89, %90, %91) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %93 : Float(256, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>]() # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %96 : Char(256, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::QuantizeLinear[axis=0](%layer1.downsample.0.weight, %93, %106)\n",
      "  %97 : Float(256, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0) = onnx::DequantizeLinear[axis=0](%96, %93, %106) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %98 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%92, %97) # /usr/local/lib/python3.8/dist-packages/pytorch_quantization/nn/modules/quant_conv.py:130:0\n",
      "  %99 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%98, %layer1.downsample.1.weight, %layer1.downsample.1.bias, %layer1.downsample.1.running_mean, %layer1.downsample.1.running_var)\n",
      "  %100 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::Add(%86, %99) # /usr/local/lib/python3.8/dist-packages/torchvision/models/resnet.py:138:0\n",
      "  %output : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=0, device=cuda:0) = onnx::Relu(%100) # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1297:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.zeros((1, 3, 224, 224)).to(\"cuda\")\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "quant_nn.TensorQuantizer.use_fb_fake_quant = True\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(model, input1, \"resnet50_replace.onnx\", \n",
    "                      verbose=True, \n",
    "                      input_names=[\"input\"], \n",
    "                      output_names=[\"output\"], \n",
    "                      opset_version=13, \n",
    "                      do_constant_folding=True)\n",
    "quant_nn.TensorQuantizer.use_fb_fake_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 创建一个只有resnet  layer1[0]及之前部分的网络\n",
    "# class myModel2(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(myModel2, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 5, 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.conv1(x)\n",
    "\n",
    "# model2 = myModel2()\n",
    "# model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# quantize.replace_to_quantization_module(model2)\n",
    "# quantize.set_quantizer_fast(model2)\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# a = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# images = [a, a, a, a]\n",
    "# quantize.calibrate_model(model2, images, \"cpu\", None, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input1 = torch.randn((1, 3, 224, 224)).to(\"cuda\").to(torch.float32)\n",
    "# model2.to(\"cuda\").to(torch.float32)\n",
    "# # model2.eval()\n",
    "# quant_nn.TensorQuantizer.use_fb_fake_quant = True\n",
    "# with torch.no_grad():\n",
    "#     torch.onnx.export(model2, input1, \"aaaa.onnx\", \n",
    "#                       verbose=True, \n",
    "#                       input_names=[\"input\"], \n",
    "#                       output_names=[\"output\"], \n",
    "#                       opset_version=13, \n",
    "#                       do_constant_folding=False)\n",
    "# quant_nn.TensorQuantizer.use_fb_fake_quant = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
