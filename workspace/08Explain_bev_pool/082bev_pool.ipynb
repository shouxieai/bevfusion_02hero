{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b1b4b2-555b-4a8c-b919-fefbaf8a4076",
   "metadata": {},
   "source": [
    "- 1. 如果根据使用技术区分\n",
    "    - 1. 第一个阶段为使用pytorch、torch.autograd.Function编写的自定义函数\n",
    "         - LSS\n",
    "    - 2. 第二个阶段为使用了C++扩展\n",
    "    - 3. 第三个阶段为使用了C++ 以及 cuda扩展\n",
    "         - buvfusion\n",
    "         - nvidia-bevfusion\n",
    "        \n",
    "https://pytorch.org/tutorials/advanced/cpp_extension.html#writing-a-mixed-c-cuda-extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f839e0-7857-4585-9a01-4be68196409d",
   "metadata": {},
   "source": [
    "# 第一阶段LSS中的bev_pool\n",
    "- 技术点：使用了custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f6d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "253b6a11-7192-446b-90e3-39ffadab56ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4909d5f8-ac54-411d-aaeb-d91a042887c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1834995, 80])\n",
      "torch.Size([1834995, 4])\n",
      "torch.Size([1834995])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "x.pkl，是第一个sample的，QuickCumsumCuda中导出的x的数据\n",
    "geom_feats.pkl，是第一个sample的，QuickCumsumCuda中导出的x的数据\n",
    "ranks.pkl，是第一个sample的，QuickCumsumCuda中导出的x的数据\n",
    "\"\"\"\n",
    "with open(\"x.pkl\", \"rb\") as f:\n",
    "    content = f.read()\n",
    "    x = pickle.loads(content)\n",
    "x = x.to(\"cpu\")\n",
    "print(x.shape)\n",
    "\n",
    "with open(\"geom_feats.pkl\", \"rb\") as f:\n",
    "    content = f.read()\n",
    "    geom_feats = pickle.loads(content)\n",
    "geom_feats = geom_feats.to(\"cpu\")\n",
    "print(geom_feats.shape)\n",
    "\n",
    "with open(\"ranks.pkl\", \"rb\") as f:\n",
    "    content = f.read()\n",
    "    ranks = pickle.loads(content)\n",
    "ranks = ranks.to(\"cpu\")\n",
    "print(ranks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eae140b-afc3-4443-ac16-292d14aa49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickCumsum(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, geom_feats, ranks):\n",
    "        x = x.cumsum(0)\n",
    "        kept = torch.ones(x.shape[0], device=x.device, dtype=torch.bool)\n",
    "        kept[:-1] = ranks[1:] != ranks[:-1]\n",
    "\n",
    "        x, geom_feats = x[kept], geom_feats[kept]\n",
    "        x = torch.cat((x[:1], x[1:] - x[:-1]))\n",
    "\n",
    "        # save kept for backward\n",
    "        ctx.save_for_backward(kept) # x在backward中用不到，所以不用存\n",
    "\n",
    "        # no gradient for geom_feats\n",
    "        ctx.mark_non_differentiable(geom_feats)\n",
    "\n",
    "        return x, geom_feats\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, gradx, gradgeom):\n",
    "        (kept,) = ctx.saved_tensors\n",
    "        back = torch.cumsum(kept, 0) # cumulative sum\n",
    "        back[kept] -= 1\n",
    "\n",
    "        val = gradx[back]\n",
    "\n",
    "        return val, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fd4c90c-347f-48de-ae71-98ed859f2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, geom_feats = QuickCumsum.apply(x, geom_feats, ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376d6917-62fd-4578-afd2-aef26608237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([107208, 80])\n",
      "torch.Size([107208, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(geom_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c73e5-e092-40b9-9d05-67919f24662a",
   "metadata": {},
   "source": [
    "# 后期cpu时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c17d40-dbdc-4dfe-abbf-e5117c2ce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "batch_size = 16\n",
    "input_features = 32\n",
    "state_size = 128\n",
    "\n",
    "X = torch.randn(batch_size, input_features)\n",
    "h = torch.randn(batch_size, state_size)\n",
    "C = torch.randn(batch_size, state_size)\n",
    "\n",
    "rnn = LLTM(input_features, state_size)\n",
    "\n",
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(100000):\n",
    "    start = time.time()\n",
    "    new_h, new_C = rnn(X, (h, C))\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (new_h.sum() + new_C.sum()).backward()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} s | Backward {:.3f} s'.format(forward, backward))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae58d6e-20fe-4d19-a625-c16c690dead6",
   "metadata": {},
   "source": [
    "# 后期GPU时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7517429-f769-49ef-b77a-eb801a25af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")  # device object representing GPU\n",
    "\n",
    "batch_size = 16\n",
    "input_features = 32\n",
    "state_size = 128\n",
    "\n",
    "# Note the device=cuda_device arguments here\n",
    "X = torch.randn(batch_size, input_features, device=cuda_device)\n",
    "h = torch.randn(batch_size, state_size, device=cuda_device)\n",
    "C = torch.randn(batch_size, state_size, device=cuda_device)\n",
    "\n",
    "rnn = LLTM(input_features, state_size).to(cuda_device)\n",
    "\n",
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(100000):\n",
    "    start = time.time()\n",
    "    new_h, new_C = rnn(X, (h, C))\n",
    "    torch.cuda.synchronize()\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (new_h.sum() + new_C.sum()).backward()\n",
    "    torch.cuda.synchronize()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e5, backward * 1e6/1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc93546",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bev_pool_ext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbev_pool_ext\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bev_pool_ext'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
